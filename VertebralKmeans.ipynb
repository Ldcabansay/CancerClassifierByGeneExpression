{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, struct\n",
    "import matplotlib as plt\n",
    "from array import array as pyarray\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import pandas as pd\n",
    "from pylab import *\n",
    "import scipy.sparse as sparse\n",
    "import scipy.linalg as linalg\n",
    "import random\n",
    "\n",
    "def readExcelSheet1(excelfile):\n",
    "    from pandas import read_excel\n",
    "    return (read_excel(excelfile)).values\n",
    "\n",
    "#This function is used in the function readExcel(...) defined further below\n",
    "def readExcelRange(excelfile,sheetname=\"Sheet1\",startrow=1,endrow=1,startcol=1,endcol=1):\n",
    "    from pandas import read_excel\n",
    "    values=(read_excel(excelfile, sheetname,header=None)).values;\n",
    "    return values[startrow-1:endrow,startcol-1:endcol]\n",
    "\n",
    "#This is the function you can actually use within your program.\n",
    "#See manner of usage further below in the section \"Prepare Data\"\n",
    "\n",
    "def readExcel(excelfile,**args):\n",
    "    if args:\n",
    "        data=readExcelRange(excelfile,**args)\n",
    "    else:\n",
    "        data=readExcelSheet1(excelfile)\n",
    "    if data.shape==(1,1):\n",
    "        return data[0,0]\n",
    "    elif (data.shape)[0]==1:\n",
    "        return data[0]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def writeExcelData(x,excelfile,sheetname,startrow,startcol):\n",
    "    from pandas import DataFrame, ExcelWriter\n",
    "    from openpyxl import load_workbook\n",
    "    df=DataFrame(x)\n",
    "    book = load_workbook(excelfile)\n",
    "    writer = ExcelWriter(excelfile, engine='openpyxl') \n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    df.to_excel(writer, sheet_name=sheetname,startrow=startrow-1, startcol=startcol-1, header=False, index=False)\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "\n",
    "def getSheetNames(excelfile):\n",
    "    from pandas import ExcelFile\n",
    "    return (ExcelFile(excelfile)).sheet_names\n",
    "sheetname = 'Results'\n",
    "startcol = 2\n",
    "excelfile=r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/UBX - Machine Learning w: Python/FinalProject/KmeansResults.xlsx\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Implementing Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#K-means functions\n",
    "def cluster_points(X, mu):\n",
    "    clusters  = {}\n",
    "    for x in X:\n",
    "        mukey = min([(i[0], np.linalg.norm(x[:-1]-mu[i[0]])) \\\n",
    "                    for i in enumerate(mu)], key=lambda t:t[1])\n",
    "        bestmukey = mukey[0]\n",
    "        try:\n",
    "            clusters[bestmukey].append(x)\n",
    "        except KeyError:\n",
    "            clusters[bestmukey] = [x]\n",
    "    return clusters\n",
    " \n",
    "def reevaluate_centers(mu, clusters):\n",
    "    newmu = []\n",
    "    keys = sorted(clusters.keys())\n",
    "    for k in keys:\n",
    "        newmu.append(np.mean(np.array(clusters[k])[:,:-1], axis = 0))\n",
    "    return newmu\n",
    " \n",
    "def has_converged(mu, oldmu):\n",
    "    return (set([tuple(a) for a in mu]) == set([tuple(a) for a in oldmu]))\n",
    " \n",
    "def find_centers(X, K):\n",
    "    # Initialize to K random centers\n",
    "    # Set seed to maintain results\n",
    "    random.seed(4564)\n",
    "    oldmu = random.sample(X[:,:-1], K)\n",
    "    mu = random.sample(X[:,:-1], K)\n",
    "    while not has_converged(mu, oldmu):\n",
    "        oldmu = mu\n",
    "        # Assign all points in X to clusters\n",
    "        clusters = cluster_points(X, mu)\n",
    "        # Reevaluate centers\n",
    "        mu = reevaluate_centers(oldmu, clusters)\n",
    "    return (clusters)\n",
    "\n",
    "def resultKmeansClassLabels(Dataset, k, classlabels):#cluster must have cluster label\n",
    "    DataClusters = find_centers(Dataset, k)\n",
    "    print 'Numer of Clusters = '+repr(k)\n",
    "    print 'Class labels: '+ repr(classlabels)\n",
    "    for i in range(k):\n",
    "        Cluster = np.array(DataClusters[i])\n",
    "        print 'Cluster'+repr(i+1)+':'\n",
    "        for j in range(len(classlabels)):\n",
    "            label = Cluster[Cluster[:,-1] == classlabels[j]]\n",
    "            print repr(classlabels[j])+ ': '+ repr(len(label))\n",
    "        print 'Total Cluster Size: '+ repr(len(Cluster))\n",
    "        \n",
    "    return np.array(DataClusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and subset to training and testing sets\n",
    "**subsets not needed for Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310, 7)\n",
      "(310, 7)\n"
     ]
    }
   ],
   "source": [
    "#import 2C data\n",
    "v2C=r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/UBX - Machine Learning w: Python/FinalProject/vertebral_2C.xlsx\"\n",
    "#import 3C data\n",
    "v3C =r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/UBX - Machine Learning w: Python/FinalProject/vertebral_3C.xlsx\"\n",
    "#import matrices with class labels\n",
    "vdata2C=np.array(readExcel(v2C))\n",
    "vdata3C=np.array(readExcel(v3C))\n",
    "\n",
    "print vdata2C.shape\n",
    "print vdata3C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run K-means on V2Class Data, k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of Clusters = 2\n",
      "Class labels: ['AB', 'NO']\n",
      "Cluster1:\n",
      "'AB': 102\n",
      "'NO': 99\n",
      "Total Cluster Size: 201\n",
      "Cluster2:\n",
      "'AB': 108\n",
      "'NO': 1\n",
      "Total Cluster Size: 109\n"
     ]
    }
   ],
   "source": [
    "V2Classlabels = ['AB','NO']\n",
    "V2Clusters = resultKmeansClassLabels(vdata2C, 2, V2Classlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run K-means on V3Class Data, k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of Clusters = 3\n",
      "Class labels: ['DH', 'SL', 'NO']\n",
      "Cluster1:\n",
      "'DH': 0\n",
      "'SL': 56\n",
      "'NO': 0\n",
      "Total Cluster Size: 56\n",
      "Cluster2:\n",
      "'DH': 58\n",
      "'SL': 13\n",
      "'NO': 89\n",
      "Total Cluster Size: 160\n",
      "Cluster3:\n",
      "'DH': 2\n",
      "'SL': 81\n",
      "'NO': 11\n",
      "Total Cluster Size: 94\n"
     ]
    }
   ],
   "source": [
    "V3Classlabels = ['DH','SL','NO']\n",
    "V2Clusters = resultKmeansClassLabels(vdata3C, 3, V3Classlabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
