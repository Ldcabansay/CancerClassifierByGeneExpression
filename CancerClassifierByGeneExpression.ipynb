{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this program I've built a bayesian classifier for cancer types:'GBM','LAML','LGG','PAAD','PRAD'. The features selected for classification were gene expression values (via TCGA) of 11 genes chosen for their role in immune function or known association with certain cancer types. The goal was to determine whether a bayesian classifier could classify a cancer type based on the expression values of these 11 genes. \n",
    "\n",
    "Preliminary results with this classifer show a high accuracy (90-94%) of cancer type prediction depending on number of principle components used to train classifier. The cancer dataset consisted of the gene expression values of 11 genes from 1532 patients across 5 cancer types ('GBM','LAML','LGG','PAAD','PRAD' ).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, struct\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import pandas as pd\n",
    "from pylab import *\n",
    "import random\n",
    "import operator\n",
    "from array import array as pyarray\n",
    "\n",
    "def readExcelSheet1(excelfile):\n",
    "    from pandas import read_excel\n",
    "    return (read_excel(excelfile)).values\n",
    "\n",
    "#This function is used in the function readExcel(...) defined further below\n",
    "def readExcelRange(excelfile,sheetname=\"Sheet1\",startrow=1,endrow=1,startcol=1,endcol=1):\n",
    "    from pandas import read_excel\n",
    "    values=(read_excel(excelfile, sheetname,header=None)).values;\n",
    "    return values[startrow-1:endrow,startcol-1:endcol]\n",
    "\n",
    "#This is the function you can actually use within your program.\n",
    "#See manner of usage further below in the section \"Prepare Data\"\n",
    "\n",
    "def readExcel(excelfile,**args):\n",
    "    if args:\n",
    "        data=readExcelRange(excelfile,**args)\n",
    "    else:\n",
    "        data=np.array(readExcelSheet1(excelfile))\n",
    "    if data.shape==(1,1):\n",
    "        return data[0,0]\n",
    "    elif (data.shape)[0]==1:\n",
    "        return data[0]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def writeExcelData(x,excelfile,sheetname,startrow,startcol):\n",
    "    from pandas import DataFrame, ExcelWriter\n",
    "    from openpyxl import load_workbook\n",
    "    df=DataFrame(x)\n",
    "    book = load_workbook(excelfile)\n",
    "    writer = ExcelWriter(excelfile, engine='openpyxl') \n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    df.to_excel(writer, sheet_name=sheetname,startrow=startrow-1, startcol=startcol-1, header=False, index=False)\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "\n",
    "def getSheetNames(excelfile):\n",
    "    from pandas import ExcelFile\n",
    "    return (ExcelFile(excelfile)).sheet_names\n",
    "sheetname = 'Results'\n",
    "startcol = 2\n",
    "excelfile=r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/CancerHackers/CancerGeneData.xlsx\";\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Randomized Test/Train Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestTrainDataSplit(dataset, split):#dataset = full dataset; \n",
    "    #split = percent of dataset to be training set (enter as decimal)\n",
    "    trainingSet = []\n",
    "    testSet = []\n",
    "    for x in range(len(dataset)):\n",
    "            dataset[x] = dataset[x]\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "    return np.array(trainingSet), np.array(testSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XUZCVPR(dataset, Utrain, train):\n",
    "    #this function runs a principle components analysis on the data set where X is the data matrix without class labels\n",
    "    X = np.array(dataset)\n",
    "    #compute mean vector, U\n",
    "    if train==True:\n",
    "        Uvector = np.mean(X,axis=0)\n",
    "        U = np.array([Uvector])\n",
    "    else: \n",
    "        U=Utrain\n",
    "    #compute mean difference vector Z\n",
    "    Z = X - U \n",
    "    meanZ = np.mean(Z,axis=0) # axis to calculate column means, should be 0\n",
    "    meanZround = [round(x) for x in meanZ]\n",
    "    emptymeanZ=filter(lambda x:x != 0, meanZround) # all the column mean of z should be 0\n",
    "    \n",
    "    #covariance matrix, C\n",
    "    C = np.cov(Z.astype(float),rowvar=False)\n",
    "    Ctranspose = C.transpose()\n",
    "    checkC = np.array_equal(C,Ctranspose) #make sure covariance matrix has NxN dimensions\n",
    "    \n",
    "    aEighV=LA.eigh(C)#eigen values in decending order\n",
    "    V = flipud(aEighV[1].T)\n",
    "    Evals = flipud(aEighV[0])#Evals = eigen values\n",
    "    Vrows = V[0,:]\n",
    "    checkVrows = (np.dot(C, Vrows))/(Evals[0]*Vrows)#verifies that the rows (not columns) of matrix are eigen vectors\n",
    "    \n",
    "    P=np.dot(Z,V.T) #Principle components projection matrix\n",
    "    R=np.dot(P,V)\n",
    "    Xrec = R+U #recover X (using all principle components) to verify successful PCA\n",
    "    #once Xrec has been verified for all components, use DimensionReduction() to see the difference between X and Xrec\n",
    "    #using differing princple components (ex: top 2, 5, 10etc)\n",
    "    \n",
    "    print 'X-shape: ' +repr(X.shape)\n",
    "    print 'U-shape: ' +repr(U.shape)\n",
    "    print 'Z-shape: ' +repr(Z.shape)\n",
    "    print 'C-shape: ' +repr(C.shape)\n",
    "    print 'V-shape: ' +repr(V.shape)\n",
    "    print 'P-shape: ' +repr(P.shape)\n",
    "    print 'R-shape: ' +repr(R.shape)\n",
    "    print 'Xrec-shape: '+ repr(Xrec.shape)\n",
    "    print 'meanZround: ' + repr(meanZround)\n",
    "    print 'emptymeanZ: ' + repr(emptymeanZ)\n",
    "    print 'C equals C.T : ' + repr(checkC)\n",
    "    print 'Rows are eigenvectors if values are 1: ' + repr(checkVrows)    \n",
    "    print 'Note: Eigenvectors and values returned in order most to least importance'\n",
    "    return np.array(X), np.array(U), np.array(Z), np.array(C), np.array(V), np.array(Evals), np.array(P), np.array(R), np.array(Xrec)\n",
    "#[X,U,Z, C, V, Evals, P, R, Xrec]\n",
    "\n",
    "def DimensionReduction(X, P, V, U):\n",
    "    reducedDims = []\n",
    "    Xdiffavg = []\n",
    "    for d in range(len(U.T)):\n",
    "        i = d+1\n",
    "        Xrec = (np.dot(P[:,0:i],V[0:i,:]))+U\n",
    "        reducedDims.append(np.array(Xrec))\n",
    "\n",
    "    for m in range(len(U.T)):\n",
    "        Xdiffnorms = []\n",
    "        for w in range(len(X)):\n",
    "            tXdim = reducedDims[m][w]\n",
    "            Xdiffs = X[w]-tXdim\n",
    "            normXdiff = LA.norm(Xdiffs)\n",
    "            Xdiffnorms.append(normXdiff)\n",
    "        meanXdiff = np.mean(Xdiffnorms)\n",
    "        Xdiffavg.append(meanXdiff)\n",
    "    return np.array(Xdiffavg)\n",
    "\n",
    "def printPCAresults(results, numPC):\n",
    "    for a in range(numPC):\n",
    "        print 'Using '+repr(a+1)+' principle component(s) the average difference between X and Xrec is '+repr(results[a]) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Classifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BuildNDBayesianClassifier(Dataset, Classlabels, D):\n",
    "    ClassStats = {}\n",
    "    for n in range(len(Classlabels)):\n",
    "        ClassStats[Classlabels[n]]={}\n",
    "        Class = Dataset[Dataset[:,-1] == Classlabels[n]]\n",
    "        ClassData = (Class[:,:D]).astype(float)\n",
    "        ClassStats[Classlabels[n]]['Num'] = len(Class)\n",
    "        ClassStats[Classlabels[n]]['Data'] = ClassData\n",
    "        ClassStats[Classlabels[n]]['Mean'] = np.mean(ClassData,axis=0)\n",
    "        ClassStats[Classlabels[n]]['Cov'] = np.cov(ClassData, rowvar=False)\n",
    "    return ClassStats\n",
    "    \n",
    "\n",
    "def ApplyNDBayesianClassifier(TestDataset, TrainDataset, Classlabels, D):\n",
    "    ClassStats = BuildNDBayesianClassifier(TrainDataset, Classlabels, D)\n",
    "    w=1; #width of the bin\n",
    "    CountC_all = []\n",
    "    for n in range(len(Classlabels)):\n",
    "        NC = ClassStats[Classlabels[n]]['Num']\n",
    "        UC = ClassStats[Classlabels[n]]['Mean']\n",
    "        covC = ClassStats[Classlabels[n]]['Cov']\n",
    "        testset = np.array((TestDataset[:,:D])).astype(float)\n",
    "        countC = NC*w*pdf(testset, UC, covC)\n",
    "        #print countC\n",
    "        CountC_all.append(countC)\n",
    "    [resultlabel, resultprob]= ResultLPBayesClassifier(CountC_all, TestDataset, Classlabels)\n",
    "    return np.array([resultlabel, resultprob])\n",
    "\n",
    "def ResultLPBayesClassifier(CountC_all, TestDataset, Classlabels):\n",
    "    ClassCounts_all = np.array(CountC_all)\n",
    "    print ClassCounts_all.shape\n",
    "    resultlabel = np.full(np.alen(TestDataset), \"Indeterminate\", dtype=object)\n",
    "    resultprob = np.full(np.alen(TestDataset), 0 , dtype=float)\n",
    "    for g in range(len(TestDataset)):\n",
    "        CountXvalues = []\n",
    "        for w in range(len(Classlabels)):\n",
    "            count = ClassCounts_all[w][g]\n",
    "            CountXvalues.append(count)\n",
    "        max_value = max(CountXvalues)\n",
    "        max_index = CountXvalues.index(max_value)\n",
    "        label = Classlabels[max_index]\n",
    "        resultlabel[g]=label\n",
    "        #print sum(ClassCounts_all)\n",
    "        resultprob = (ClassCounts_all[max_index][g]).astype('float')/sum(ClassCounts_all)\n",
    "    return resultlabel, resultprob\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pdf(x,mu,sigma):\n",
    "    #print x\n",
    "    #print mu\n",
    "    xf = x.astype(float)\n",
    "    muf = mu.astype(float)\n",
    "\n",
    "    d=np.alen(muf)\n",
    "    dfact1=(2*np.pi)**d\n",
    "    dfact2=LA.det(sigma)\n",
    "    fact=1/np.sqrt(dfact1*dfact2)\n",
    "    xc=xf-muf\n",
    "    isigma=LA.inv(sigma)\n",
    "#    isigxc = np.dot(isigma,xc.T)\n",
    "#    ex = np.dot(xc,isigxc)\n",
    "    npdf = fact * np.exp(-0.5 * np.einsum('ij,jk,ik->i',xc,isigma,xc))\n",
    "    return npdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics: Functions to Evaluate and Print Bayes Classifier Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PerformanceMetrics(Resultlabels, Dataset, PositiveLabel, Classlabels):\n",
    "    OutputCL = (Resultlabels).astype('str')\n",
    "    GroundTruth = (Dataset[:,-1]).astype('str')\n",
    "    Classcomps = OutputCL == GroundTruth\n",
    "    #print Classcomps    \n",
    "    TrueP=0\n",
    "    FalseP=0\n",
    "    TrueN=0\n",
    "    FalseN=0\n",
    "    Num=0\n",
    "    for i in range(len(GroundTruth)):\n",
    "        if Classcomps[i]== True:\n",
    "            if OutputCL[i] == PositiveLabel:\n",
    "                TrueP+=1\n",
    "            else:\n",
    "                TrueN+=1\n",
    "        elif Classcomps[i]==False:\n",
    "            if OutputCL[i] != PositiveLabel:\n",
    "                FalseN+=1\n",
    "            else:\n",
    "                FalseP+=1\n",
    "    Accuracy = float((TrueP+TrueN))/(TrueP+TrueN+FalseP+FalseN)\n",
    "    Sensitivity = float((TrueP))/(TrueP+FalseN)\n",
    "    Specificity = float((TrueN))/(FalseP+TrueN)\n",
    "    if (TrueP+FalseP)==0:\n",
    "        PPV = 'No Positive Predictions'\n",
    "    else: \n",
    "        PPV = float((TrueP))/(TrueP+FalseP)\n",
    "    stringmeasures = ['TrueP', 'FalseP', 'TrueN', 'FalseN', 'Accuracy','Sensitivity', 'Specificity','PPV']\n",
    "    measures_values = [TrueP, FalseP, TrueN, FalseN, Accuracy, Sensitivity, Specificity, PPV]\n",
    "    print 'Classifier Performance:'\n",
    "    print '     Positive Class Label: '+ repr(PositiveLabel)\n",
    "    for i in range(len(stringmeasures)):\n",
    "        print '         '+stringmeasures[i]+ ': '+repr(measures_values[i])\n",
    "    \n",
    "    return [TrueP, FalseP, TrueN, FalseN, Accuracy, Sensitivity, Specificity, PPV]\n",
    "\n",
    "\n",
    "def BayesPCAperformance(TestDataset, TrainDataset, Classlabels, dimensions, allD):\n",
    "    BayesPCAperformance =[]\n",
    "    DResults=EvaluateBayesPCA(TestDataset, TrainDataset, Classlabels, dimensions, allD)\n",
    "    PC=len(DResults)\n",
    "    if allD==False:\n",
    "        PC = 1\n",
    "    for i in range(PC):\n",
    "        if allD==False:\n",
    "            print repr(dimensions)+' Principal Components Bayes Classifier Performance:'\n",
    "        else:\n",
    "            print repr(i+2)+' Principal Components Bayes Classifier Performance:'\n",
    "            \n",
    "        labelstring = []\n",
    "        reallabelstring = []\n",
    "        OutputCL = (DResults[i][0]).astype('str')\n",
    "        realCL=(TrainDataset[:,-1]).astype('str')\n",
    "        for j in range(len(Classlabels)):\n",
    "            labelnum = OutputCL[OutputCL == Classlabels[j]]\n",
    "            lstring = repr(Classlabels[j])+ ': '+ repr(len(labelnum))\n",
    "            labelstring.append(lstring)\n",
    "            reallabelnum = realCL[realCL == Classlabels[j]]\n",
    "            reallstring = repr(Classlabels[j])+ ': '+ repr(len(reallabelnum))\n",
    "            reallabelstring.append(reallstring)\n",
    "        print '  Training Output ->' + repr(reallabelstring) + ' Total: ' +repr(len(realCL))\n",
    "        print '  Testing Output -->' + repr(labelstring)+ ' Total: ' +repr(len(OutputCL))\n",
    "        totalPPV = []\n",
    "        for cl in range(len(Classlabels)):\n",
    "            PositiveLabel=Classlabels[cl]\n",
    "            if allD==True:\n",
    "                nDBayesPerformance = PerformanceMetrics(DResults[i][0], TestDataset, PositiveLabel, Classlabels)\n",
    "                totalPPV.append(nDBayesPerformance[-1])\n",
    "            else:\n",
    "                nDBayesPerformance = PerformanceMetrics(DResults[0], TestDataset, PositiveLabel, Classlabels)\n",
    "                totalPPV.append(nDBayesPerformance[-1])\n",
    "            BayesPCAperformance.append(nDBayesPerformance)\n",
    "        \n",
    "        print 'Avg PPV: '+ repr(np.mean(totalPPV))   \n",
    "        print '\\n'\n",
    "    return np.array(BayesPCAperformance)\n",
    "\n",
    "def EvaluateBayesPCA(TestDataset, TrainDataset, Classlabels, dimensions, allD):\n",
    "    DBayesPCAResults=[]\n",
    "    if allD == True: \n",
    "        for d in range(dimensions-1):\n",
    "            D=d+2\n",
    "            nBResults = ApplyNDBayesianClassifier(TestDataset, TrainDataset, Classlabels, D)\n",
    "            DBayesPCAResults.append(nBResults)\n",
    "        return np.array(DBayesPCAResults)\n",
    "    else:\n",
    "        D=dimensions\n",
    "        nBResults = ApplyNDBayesianClassifier(TestDataset, TrainDataset, Classlabels, D)\n",
    "        return np.array(nBResults)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function: Load Data, Run PCA, Run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1532, 12)\n",
      "[[630.0 44776.0 64147.0 ..., 6080.0 5599.0 u'GBM']\n",
      " [792.0 62668.0 3048.0 ..., 2575.0 1633.0 u'GBM']\n",
      " [1114.0 77348.0 11210.0 ..., 3055.0 2302.0 u'GBM']\n",
      " ..., \n",
      " [372.6402 29000.0 7155.9508 ..., 1047.3324 1806.5663 u'PRAD']\n",
      " [308.6948 20300.5498 3498.2692 ..., 1344.7363 1768.6825 u'PRAD']\n",
      " [219.1653 23697.2099 6139.7373 ..., 1462.0347 1892.2826 u'PRAD']]\n",
      "(512, 12)\n"
     ]
    }
   ],
   "source": [
    "cdata=np.array(readExcel(excelfile))\n",
    "print cdata.shape\n",
    "#print cdata[:5,:]\n",
    "random.seed(8)\n",
    "[CTrain, CTest]=TestTrainDataSplit(cdata, 0.66)\n",
    "print CTrain\n",
    "print CTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-shape: (1020, 11)\n",
      "U-shape: (1, 11)\n",
      "Z-shape: (1020, 11)\n",
      "C-shape: (11, 11)\n",
      "V-shape: (11, 11)\n",
      "P-shape: (1020, 11)\n",
      "R-shape: (1020, 11)\n",
      "Xrec-shape: (1020, 11)\n",
      "meanZround: [-0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0, 0.0, -0.0]\n",
      "emptymeanZ: []\n",
      "C equals C.T : True\n",
      "Rows are eigenvectors if values are 1: array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
      "Note: Eigenvectors and values returned in order most to least importance\n"
     ]
    }
   ],
   "source": [
    "[X10,U10,Z10, C10, V10, Evals10, P10, R10, Xrec10] = XUZCVPR(CTrain[:,:-1], Utrain=1, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 principle component(s) the average difference between X and Xrec is 7257.2388186280914\n",
      "Using 2 principle component(s) the average difference between X and Xrec is 3632.5150552861355\n",
      "Using 3 principle component(s) the average difference between X and Xrec is 2519.5969502507114\n",
      "Using 4 principle component(s) the average difference between X and Xrec is 1822.3653849135153\n",
      "Using 5 principle component(s) the average difference between X and Xrec is 1373.7659988263226\n",
      "Using 6 principle component(s) the average difference between X and Xrec is 1014.6559452189041\n",
      "Using 7 principle component(s) the average difference between X and Xrec is 755.40956359763697\n",
      "Using 8 principle component(s) the average difference between X and Xrec is 463.5205785975557\n",
      "Using 9 principle component(s) the average difference between X and Xrec is 256.22913484231174\n",
      "Using 10 principle component(s) the average difference between X and Xrec is 156.05535826736519\n",
      "Using 11 principle component(s) the average difference between X and Xrec is 9.2671541086153326e-12\n"
     ]
    }
   ],
   "source": [
    "#Run PCA and view results for X and Xrec depending on number of principle components used\n",
    "#WARNING: this function can be memory intensive depending on size of dataset\n",
    "C10resultsPCA= DimensionReduction(X10, P10, V10, U10)\n",
    "printPCAresults(C10resultsPCA, numPC=11) #check data set for how large X values are, if avg diff makes sense\n",
    "#smallest X-Xrec difference will give best classification results.\n",
    "#dimension reduction might not be possible in some datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1020)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainClabels = (CTrain[:,-1][...][None]).astype(str)#training set labels\n",
    "testClabels = (CTest[:,-1][...][None]).astype(str) #test set labels\n",
    "clabels= np.array(['GBM','LAML','LGG','PAAD','PRAD']) #classes by cancer gene tcga name \n",
    "trainClabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 11)\n"
     ]
    }
   ],
   "source": [
    "testCZ=(CTest[:,:-1])-U10\n",
    "#subtract meanvector from testvals\n",
    "V10.shape\n",
    "testC5 = dot(testCZ,V10.T)\n",
    "#get p vector for test\n",
    "print testC5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 12)\n"
     ]
    }
   ],
   "source": [
    "trainOnco = np.concatenate((P10, trainClabels.T), axis=1)\n",
    "print trainOnco.shape\n",
    "#print trainOnco[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 12)\n"
     ]
    }
   ],
   "source": [
    "testOnco = np.concatenate((testC5, testClabels.T), axis=1)\n",
    "print testOnco.shape\n",
    "#print testOnco[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 512)\n",
      "8 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'GBM': 107\", \"'LAML': 102\", \"'LGG': 346\", \"'PAAD': 137\", \"'PRAD': 328\"] Total: 1020\n",
      "  Testing Output -->[\"'GBM': 1\", \"'LAML': 1\", \"'LGG': 1\", \"'PAAD': 1\", \"'PRAD': 1\"] Total: 3\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'GBM'\n",
      "         TrueP: 35\n",
      "         FalseP: 12\n",
      "         TrueN: 435\n",
      "         FalseN: 30\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.5384615384615384\n",
      "         Specificity: 0.9731543624161074\n",
      "         PPV: 0.7446808510638298\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LAML'\n",
      "         TrueP: 67\n",
      "         FalseP: 0\n",
      "         TrueN: 403\n",
      "         FalseN: 42\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.6146788990825688\n",
      "         Specificity: 1.0\n",
      "         PPV: 1.0\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LGG'\n",
      "         TrueP: 171\n",
      "         FalseP: 13\n",
      "         TrueN: 299\n",
      "         FalseN: 29\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.855\n",
      "         Specificity: 0.9583333333333334\n",
      "         PPV: 0.9293478260869565\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PAAD'\n",
      "         TrueP: 36\n",
      "         FalseP: 9\n",
      "         TrueN: 434\n",
      "         FalseN: 33\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.5217391304347826\n",
      "         Specificity: 0.9796839729119639\n",
      "         PPV: 0.8\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PRAD'\n",
      "         TrueP: 161\n",
      "         FalseP: 8\n",
      "         TrueN: 309\n",
      "         FalseN: 34\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.8256410256410256\n",
      "         Specificity: 0.9747634069400631\n",
      "         PPV: 0.9526627218934911\n",
      "Avg PPV: 0.88533827980885549\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdimensions = 8\n",
    "allD10 = False #whether or not to show classifier results from all PCA components up to cdimensions or just in cdimensions\n",
    "MN10BayesPCAperformance = BayesPCAperformance(testOnco, trainOnco, clabels, cdimensions, allD10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 512)\n",
      "(5, 512)\n",
      "(5, 512)\n",
      "(5, 512)\n",
      "(5, 512)\n",
      "(5, 512)\n",
      "(5, 512)\n",
      "2 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'GBM': 107\", \"'LAML': 102\", \"'LGG': 346\", \"'PAAD': 137\", \"'PRAD': 328\"] Total: 1020\n",
      "  Testing Output -->[\"'GBM': 29\", \"'LAML': 86\", \"'LGG': 209\", \"'PAAD': 22\", \"'PRAD': 166\"] Total: 512\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'GBM'\n",
      "         TrueP: 25\n",
      "         FalseP: 4\n",
      "         TrueN: 368\n",
      "         FalseN: 115\n",
      "         Accuracy: 0.767578125\n",
      "         Sensitivity: 0.17857142857142858\n",
      "         Specificity: 0.989247311827957\n",
      "         PPV: 0.8620689655172413\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LAML'\n",
      "         TrueP: 69\n",
      "         FalseP: 17\n",
      "         TrueN: 324\n",
      "         FalseN: 102\n",
      "         Accuracy: 0.767578125\n",
      "         Sensitivity: 0.40350877192982454\n",
      "         Specificity: 0.9501466275659824\n",
      "         PPV: 0.8023255813953488\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LGG'\n",
      "         TrueP: 157\n",
      "         FalseP: 52\n",
      "         TrueN: 236\n",
      "         FalseN: 67\n",
      "         Accuracy: 0.767578125\n",
      "         Sensitivity: 0.7008928571428571\n",
      "         Specificity: 0.8194444444444444\n",
      "         PPV: 0.7511961722488039\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PAAD'\n",
      "         TrueP: 19\n",
      "         FalseP: 3\n",
      "         TrueN: 374\n",
      "         FalseN: 116\n",
      "         Accuracy: 0.767578125\n",
      "         Sensitivity: 0.14074074074074075\n",
      "         Specificity: 0.9920424403183024\n",
      "         PPV: 0.8636363636363636\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PRAD'\n",
      "         TrueP: 123\n",
      "         FalseP: 43\n",
      "         TrueN: 270\n",
      "         FalseN: 76\n",
      "         Accuracy: 0.767578125\n",
      "         Sensitivity: 0.6180904522613065\n",
      "         Specificity: 0.8626198083067093\n",
      "         PPV: 0.7409638554216867\n",
      "Avg PPV: 0.8040381876438889\n",
      "\n",
      "\n",
      "3 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'GBM': 107\", \"'LAML': 102\", \"'LGG': 346\", \"'PAAD': 137\", \"'PRAD': 328\"] Total: 1020\n",
      "  Testing Output -->[\"'GBM': 29\", \"'LAML': 90\", \"'LGG': 212\", \"'PAAD': 32\", \"'PRAD': 149\"] Total: 512\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'GBM'\n",
      "         TrueP: 24\n",
      "         FalseP: 5\n",
      "         TrueN: 386\n",
      "         FalseN: 97\n",
      "         Accuracy: 0.80078125\n",
      "         Sensitivity: 0.19834710743801653\n",
      "         Specificity: 0.9872122762148338\n",
      "         PPV: 0.8275862068965517\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LAML'\n",
      "         TrueP: 68\n",
      "         FalseP: 22\n",
      "         TrueN: 342\n",
      "         FalseN: 80\n",
      "         Accuracy: 0.80078125\n",
      "         Sensitivity: 0.4594594594594595\n",
      "         Specificity: 0.9395604395604396\n",
      "         PPV: 0.7555555555555555\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LGG'\n",
      "         TrueP: 162\n",
      "         FalseP: 50\n",
      "         TrueN: 248\n",
      "         FalseN: 52\n",
      "         Accuracy: 0.80078125\n",
      "         Sensitivity: 0.7570093457943925\n",
      "         Specificity: 0.8322147651006712\n",
      "         PPV: 0.7641509433962265\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PAAD'\n",
      "         TrueP: 30\n",
      "         FalseP: 2\n",
      "         TrueN: 380\n",
      "         FalseN: 100\n",
      "         Accuracy: 0.80078125\n",
      "         Sensitivity: 0.23076923076923078\n",
      "         Specificity: 0.9947643979057592\n",
      "         PPV: 0.9375\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PRAD'\n",
      "         TrueP: 126\n",
      "         FalseP: 23\n",
      "         TrueN: 284\n",
      "         FalseN: 79\n",
      "         Accuracy: 0.80078125\n",
      "         Sensitivity: 0.6146341463414634\n",
      "         Specificity: 0.9250814332247557\n",
      "         PPV: 0.8456375838926175\n",
      "Avg PPV: 0.82608605794819012\n",
      "\n",
      "\n",
      "4 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'GBM': 107\", \"'LAML': 102\", \"'LGG': 346\", \"'PAAD': 137\", \"'PRAD': 328\"] Total: 1020\n",
      "  Testing Output -->[\"'GBM': 37\", \"'LAML': 74\", \"'LGG': 193\", \"'PAAD': 44\", \"'PRAD': 164\"] Total: 512\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'GBM'\n",
      "         TrueP: 32\n",
      "         FalseP: 5\n",
      "         TrueN: 405\n",
      "         FalseN: 70\n",
      "         Accuracy: 0.853515625\n",
      "         Sensitivity: 0.3137254901960784\n",
      "         Specificity: 0.9878048780487805\n",
      "         PPV: 0.8648648648648649\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LAML'\n",
      "         TrueP: 68\n",
      "         FalseP: 6\n",
      "         TrueN: 369\n",
      "         FalseN: 69\n",
      "         Accuracy: 0.853515625\n",
      "         Sensitivity: 0.49635036496350365\n",
      "         Specificity: 0.984\n",
      "         PPV: 0.918918918918919\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LGG'\n",
      "         TrueP: 160\n",
      "         FalseP: 33\n",
      "         TrueN: 277\n",
      "         FalseN: 42\n",
      "         Accuracy: 0.853515625\n",
      "         Sensitivity: 0.7920792079207921\n",
      "         Specificity: 0.8935483870967742\n",
      "         PPV: 0.8290155440414507\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PAAD'\n",
      "         TrueP: 38\n",
      "         FalseP: 6\n",
      "         TrueN: 399\n",
      "         FalseN: 69\n",
      "         Accuracy: 0.853515625\n",
      "         Sensitivity: 0.35514018691588783\n",
      "         Specificity: 0.9851851851851852\n",
      "         PPV: 0.8636363636363636\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PRAD'\n",
      "         TrueP: 139\n",
      "         FalseP: 25\n",
      "         TrueN: 298\n",
      "         FalseN: 50\n",
      "         Accuracy: 0.853515625\n",
      "         Sensitivity: 0.7354497354497355\n",
      "         Specificity: 0.9226006191950464\n",
      "         PPV: 0.8475609756097561\n",
      "Avg PPV: 0.86479933341427073\n",
      "\n",
      "\n",
      "5 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'GBM': 107\", \"'LAML': 102\", \"'LGG': 346\", \"'PAAD': 137\", \"'PRAD': 328\"] Total: 1020\n",
      "  Testing Output -->[\"'GBM': 46\", \"'LAML': 68\", \"'LGG': 191\", \"'PAAD': 42\", \"'PRAD': 165\"] Total: 512\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'GBM'\n",
      "         TrueP: 34\n",
      "         FalseP: 12\n",
      "         TrueN: 428\n",
      "         FalseN: 38\n",
      "         Accuracy: 0.90234375\n",
      "         Sensitivity: 0.4722222222222222\n",
      "         Specificity: 0.9727272727272728\n",
      "         PPV: 0.7391304347826086\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LAML'\n",
      "         TrueP: 67\n",
      "         FalseP: 1\n",
      "         TrueN: 395\n",
      "         FalseN: 49\n",
      "         Accuracy: 0.90234375\n",
      "         Sensitivity: 0.5775862068965517\n",
      "         Specificity: 0.9974747474747475\n",
      "         PPV: 0.9852941176470589\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LGG'\n",
      "         TrueP: 171\n",
      "         FalseP: 20\n",
      "         TrueN: 291\n",
      "         FalseN: 30\n",
      "         Accuracy: 0.90234375\n",
      "         Sensitivity: 0.8507462686567164\n",
      "         Specificity: 0.9356913183279743\n",
      "         PPV: 0.8952879581151832\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PAAD'\n",
      "         TrueP: 34\n",
      "         FalseP: 8\n",
      "         TrueN: 428\n",
      "         FalseN: 42\n",
      "         Accuracy: 0.90234375\n",
      "         Sensitivity: 0.4473684210526316\n",
      "         Specificity: 0.981651376146789\n",
      "         PPV: 0.8095238095238095\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PRAD'\n",
      "         TrueP: 156\n",
      "         FalseP: 9\n",
      "         TrueN: 306\n",
      "         FalseN: 41\n",
      "         Accuracy: 0.90234375\n",
      "         Sensitivity: 0.7918781725888325\n",
      "         Specificity: 0.9714285714285714\n",
      "         PPV: 0.9454545454545454\n",
      "Avg PPV: 0.87493817310464106\n",
      "\n",
      "\n",
      "6 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'GBM': 107\", \"'LAML': 102\", \"'LGG': 346\", \"'PAAD': 137\", \"'PRAD': 328\"] Total: 1020\n",
      "  Testing Output -->[\"'GBM': 46\", \"'LAML': 67\", \"'LGG': 189\", \"'PAAD': 42\", \"'PRAD': 168\"] Total: 512\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'GBM'\n",
      "         TrueP: 36\n",
      "         FalseP: 10\n",
      "         TrueN: 431\n",
      "         FalseN: 35\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.5070422535211268\n",
      "         Specificity: 0.9773242630385488\n",
      "         PPV: 0.782608695652174\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LAML'\n",
      "         TrueP: 67\n",
      "         FalseP: 0\n",
      "         TrueN: 400\n",
      "         FalseN: 45\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.5982142857142857\n",
      "         Specificity: 1.0\n",
      "         PPV: 1.0\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LGG'\n",
      "         TrueP: 170\n",
      "         FalseP: 19\n",
      "         TrueN: 297\n",
      "         FalseN: 26\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.8673469387755102\n",
      "         Specificity: 0.939873417721519\n",
      "         PPV: 0.8994708994708994\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PAAD'\n",
      "         TrueP: 36\n",
      "         FalseP: 6\n",
      "         TrueN: 431\n",
      "         FalseN: 39\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.48\n",
      "         Specificity: 0.9862700228832952\n",
      "         PPV: 0.8571428571428571\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PRAD'\n",
      "         TrueP: 158\n",
      "         FalseP: 10\n",
      "         TrueN: 309\n",
      "         FalseN: 35\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.8186528497409327\n",
      "         Specificity: 0.9686520376175548\n",
      "         PPV: 0.9404761904761905\n",
      "Avg PPV: 0.89593972854842419\n",
      "\n",
      "\n",
      "7 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'GBM': 107\", \"'LAML': 102\", \"'LGG': 346\", \"'PAAD': 137\", \"'PRAD': 328\"] Total: 1020\n",
      "  Testing Output -->[\"'GBM': 46\", \"'LAML': 67\", \"'LGG': 190\", \"'PAAD': 43\", \"'PRAD': 166\"] Total: 512\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'GBM'\n",
      "         TrueP: 36\n",
      "         FalseP: 10\n",
      "         TrueN: 431\n",
      "         FalseN: 35\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.5070422535211268\n",
      "         Specificity: 0.9773242630385488\n",
      "         PPV: 0.782608695652174\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LAML'\n",
      "         TrueP: 67\n",
      "         FalseP: 0\n",
      "         TrueN: 400\n",
      "         FalseN: 45\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.5982142857142857\n",
      "         Specificity: 1.0\n",
      "         PPV: 1.0\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LGG'\n",
      "         TrueP: 171\n",
      "         FalseP: 19\n",
      "         TrueN: 296\n",
      "         FalseN: 26\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.868020304568528\n",
      "         Specificity: 0.9396825396825397\n",
      "         PPV: 0.9\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PAAD'\n",
      "         TrueP: 37\n",
      "         FalseP: 6\n",
      "         TrueN: 430\n",
      "         FalseN: 39\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.4868421052631579\n",
      "         Specificity: 0.9862385321100917\n",
      "         PPV: 0.8604651162790697\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PRAD'\n",
      "         TrueP: 156\n",
      "         FalseP: 10\n",
      "         TrueN: 311\n",
      "         FalseN: 35\n",
      "         Accuracy: 0.912109375\n",
      "         Sensitivity: 0.8167539267015707\n",
      "         Specificity: 0.9688473520249221\n",
      "         PPV: 0.9397590361445783\n",
      "Avg PPV: 0.89656656961516445\n",
      "\n",
      "\n",
      "8 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'GBM': 107\", \"'LAML': 102\", \"'LGG': 346\", \"'PAAD': 137\", \"'PRAD': 328\"] Total: 1020\n",
      "  Testing Output -->[\"'GBM': 47\", \"'LAML': 67\", \"'LGG': 184\", \"'PAAD': 45\", \"'PRAD': 169\"] Total: 512\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'GBM'\n",
      "         TrueP: 35\n",
      "         FalseP: 12\n",
      "         TrueN: 435\n",
      "         FalseN: 30\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.5384615384615384\n",
      "         Specificity: 0.9731543624161074\n",
      "         PPV: 0.7446808510638298\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LAML'\n",
      "         TrueP: 67\n",
      "         FalseP: 0\n",
      "         TrueN: 403\n",
      "         FalseN: 42\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.6146788990825688\n",
      "         Specificity: 1.0\n",
      "         PPV: 1.0\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'LGG'\n",
      "         TrueP: 171\n",
      "         FalseP: 13\n",
      "         TrueN: 299\n",
      "         FalseN: 29\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.855\n",
      "         Specificity: 0.9583333333333334\n",
      "         PPV: 0.9293478260869565\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PAAD'\n",
      "         TrueP: 36\n",
      "         FalseP: 9\n",
      "         TrueN: 434\n",
      "         FalseN: 33\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.5217391304347826\n",
      "         Specificity: 0.9796839729119639\n",
      "         PPV: 0.8\n",
      "Classifier Performance:\n",
      "     Positive Class Label: 'PRAD'\n",
      "         TrueP: 161\n",
      "         FalseP: 8\n",
      "         TrueN: 309\n",
      "         FalseN: 34\n",
      "         Accuracy: 0.91796875\n",
      "         Sensitivity: 0.8256410256410256\n",
      "         Specificity: 0.9747634069400631\n",
      "         PPV: 0.9526627218934911\n",
      "Avg PPV: 0.88533827980885549\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdimensions = 8\n",
    "allD10 = True #whether or not to show classifier results from all PCA components up to cdimensions or just in cdimensions\n",
    "MN10BayesPCAperformance = BayesPCAperformance(testOnco, trainOnco, clabels, cdimensions, allD10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
