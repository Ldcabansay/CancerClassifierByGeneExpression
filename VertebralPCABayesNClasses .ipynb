{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os, struct\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import pandas as pd\n",
    "from pylab import *\n",
    "import random\n",
    "import operator\n",
    "\n",
    "def readExcelSheet1(excelfile):\n",
    "    from pandas import read_excel\n",
    "    return (read_excel(excelfile)).values\n",
    "\n",
    "#This function is used in the function readExcel(...) defined further below\n",
    "def readExcelRange(excelfile,sheetname=\"Sheet1\",startrow=1,endrow=1,startcol=1,endcol=1):\n",
    "    from pandas import read_excel\n",
    "    values=(read_excel(excelfile, sheetname,header=None)).values;\n",
    "    return values[startrow-1:endrow,startcol-1:endcol]\n",
    "\n",
    "#This is the function you can actually use within your program.\n",
    "#See manner of usage further below in the section \"Prepare Data\"\n",
    "\n",
    "def readExcel(excelfile,**args):\n",
    "    if args:\n",
    "        data=readExcelRange(excelfile,**args)\n",
    "    else:\n",
    "        data=readExcelSheet1(excelfile)\n",
    "    if data.shape==(1,1):\n",
    "        return data[0,0]\n",
    "    elif (data.shape)[0]==1:\n",
    "        return data[0]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def writeExcelData(x,excelfile,sheetname,startrow,startcol):\n",
    "    from pandas import DataFrame, ExcelWriter\n",
    "    from openpyxl import load_workbook\n",
    "    df=DataFrame(x)\n",
    "    book = load_workbook(excelfile)\n",
    "    writer = ExcelWriter(excelfile, engine='openpyxl') \n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    df.to_excel(writer, sheet_name=sheetname,startrow=startrow-1, startcol=startcol-1, header=False, index=False)\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "\n",
    "def getSheetNames(excelfile):\n",
    "    from pandas import ExcelFile\n",
    "    return (ExcelFile(excelfile)).sheet_names\n",
    "sheetname = 'Results'\n",
    "startcol = 2\n",
    "excelfile=r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/UBX - Machine Learning w: Python/FinalProject/KmeansResults.xlsx\";\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 7) (113, 7)\n",
      "(196, 7) (114, 7)\n"
     ]
    }
   ],
   "source": [
    "def TestTrainDataSplit(dataset, split):#dataset = full dataset; \n",
    "    #split = percent of dataset to be training set (enter as decimal)\n",
    "    trainingSet = []\n",
    "    testSet = []\n",
    "    for x in range(len(dataset)):\n",
    "            dataset[x] = dataset[x]\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "    return np.array(trainingSet), np.array(testSet)\n",
    "\n",
    "#2C data path\n",
    "v2C=r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/UBX - Machine Learning w: Python/FinalProject/vertebral_2C.xlsx\"\n",
    "#3C data path\n",
    "v3C =r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/UBX - Machine Learning w: Python/FinalProject/vertebral_3C.xlsx\"\n",
    "#import matrices with class labels\n",
    "vdata2C=np.array(readExcel(v2C))\n",
    "vdata3C=np.array(readExcel(v3C))\n",
    "\n",
    "#set random seed to maintain results of single run\n",
    "random.seed(777)\n",
    "\n",
    "#call function to split given dataset into training and testing sets\n",
    "#note: not used for K-means as training/testing sets not needed\n",
    "[V2TrainDataset, V2TestDataset]=TestTrainDataSplit(vdata2C, 0.66)\n",
    "[V3TrainDataset, V3TestDataset]=TestTrainDataSplit(vdata3C, 0.66)\n",
    "\n",
    "#check training and test set size\n",
    "print V2TrainDataset.shape, V2TestDataset.shape\n",
    "print V3TrainDataset.shape, V3TestDataset.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XUZCVPR(dataset):\n",
    "    X = dataset\n",
    "    Uvector = np.mean(X,axis=0)\n",
    "    U = np.array([Uvector])\n",
    "    Z = X - U\n",
    "    meanZ = np.mean(Z,axis=0) # axis to calculate column means, should be 0\n",
    "    meanZround = [round(x) for x in meanZ]\n",
    "    emptymeanZ=filter(lambda x:x != 0, meanZround) # all the column mean of z should be 0\n",
    "    \n",
    "    C = np.cov(Z,rowvar=False)\n",
    "    Ctranspose = C.transpose()\n",
    "    checkC = np.array_equal(C,Ctranspose)\n",
    "    \n",
    "    aEighV=LA.eigh(C)#descending\n",
    "    V = np.flipud((aEighV[1].T))\n",
    "    Evals = np.flipud(aEighV[0])\n",
    "    Vrows = V[0,:]\n",
    "    checkVrows = (np.dot(C, Vrows))/(Evals[0]*Vrows)\n",
    "    \n",
    "    P=np.dot(Z,V.T)\n",
    "    R=np.dot(P,V)\n",
    "    Xrec = R+U\n",
    "    print 'X-shape: ' +repr(X.shape)\n",
    "    print 'U-shape: ' +repr(U.shape)\n",
    "    print 'Z-shape: ' +repr(Z.shape)\n",
    "    print 'C-shape: ' +repr(C.shape)\n",
    "    print 'V-shape: ' +repr(V.shape)\n",
    "    print 'P-shape: ' +repr(P.shape)\n",
    "    print 'R-shape: ' +repr(R.shape)\n",
    "    print 'Xrec-shape: '+ repr(Xrec.shape)\n",
    "    print 'meanZround: ' + repr(meanZround)\n",
    "    print 'emptymeanZ: ' + repr(emptymeanZ)\n",
    "    print 'C equals C.T : ' + repr(checkC)\n",
    "    print 'Rows are eigenvectors if values are 1: ' + repr(checkVrows)    \n",
    "    print 'Note: Eigenvectors and values returned in order most to least importance'\n",
    "    return np.array(X), np.array(U), np.array(Z), np.array(C), np.array(V), np.array(Evals), np.array(P), np.array(R), np.array(Xrec)\n",
    "\n",
    "def DimensionReduction(X, P, V, U):\n",
    "    reducedDims = []\n",
    "    Xdiffavg = []\n",
    "    for d in range(len(U.T)):\n",
    "        i = d+1\n",
    "        Xrec = (np.dot(P[:,0:i],V[0:i,:]))+U\n",
    "        reducedDims.append(np.array(Xrec))\n",
    "\n",
    "    for m in range(len(U.T)):\n",
    "        Xdiffnorms = []\n",
    "        for w in range(len(X)):\n",
    "            tXdim = reducedDims[m][w]\n",
    "            Xdiffs = X[w]-tXdim\n",
    "            normXdiff = LA.norm(Xdiffs)\n",
    "            Xdiffnorms.append(normXdiff)\n",
    "        meanXdiff = np.mean(Xdiffnorms)\n",
    "        Xdiffavg.append(meanXdiff)\n",
    "    for a in range(len(Xdiffavg)):\n",
    "        print 'Using '+repr(a+1)+' principle component(s) the average difference between X and Xrec is '+repr(Xdiffavg[a])    \n",
    "    return np.array(Xdiffavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pdf(x,mu,sigma):\n",
    "    #print x\n",
    "    #print mu\n",
    "    xf = x.astype(float)\n",
    "    muf = mu.astype(float)\n",
    "\n",
    "    d=np.alen(muf)\n",
    "    dfact1=(2*np.pi)**d\n",
    "    dfact2=LA.det(sigma)\n",
    "    fact=1/np.sqrt(dfact1*dfact2)\n",
    "    xc=xf-muf\n",
    "    isigma=LA.inv(sigma)\n",
    "#    isigxc = np.dot(isigma,xc.T)\n",
    "#    ex = np.dot(xc,isigxc)\n",
    "    npdf = fact * np.exp(-0.5 * np.einsum('ij,jk,ik->i',xc,isigma,xc))\n",
    "    return npdf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BuildNDBayesianClassifier(Dataset, D, Classlabels):\n",
    "    ClassStats = {}\n",
    "    for n in range(len(Classlabels)):\n",
    "        ClassStats[Classlabels[n]]={}\n",
    "        Class = Dataset[Dataset[:,-1] == Classlabels[n]]\n",
    "        ClassData = Class[:,:D]\n",
    "        ClassStats[Classlabels[n]]['Num'] = len(Class)\n",
    "        ClassStats[Classlabels[n]]['Data'] = ClassData\n",
    "        ClassStats[Classlabels[n]]['Mean'] = np.mean(ClassData,axis=0)\n",
    "        ClassStats[Classlabels[n]]['Cov'] = np.cov(ClassData, rowvar=False)\n",
    "    return ClassStats\n",
    "    \n",
    "\n",
    "def ApplyNDBayesianClassifier(TrainDataset, TestDataset, D, Classlabels):\n",
    "    ClassStats = BuildNDBayesianClassifier(TrainDataset, D, Classlabels)\n",
    "    w=1; #width of the bin\n",
    "    CountC_all = []\n",
    "    for n in range(len(Classlabels)):\n",
    "        NC = ClassStats[Classlabels[n]]['Num']\n",
    "        UC = ClassStats[Classlabels[n]]['Mean']\n",
    "        covC = ClassStats[Classlabels[n]]['Cov']\n",
    "        countC = NC*w*pdf(TestDataset[:,:D], UC, covC)\n",
    "        CountC_all.append(countC)\n",
    "    [resultlabel, resultprob]= ResultLPBayesClassifier(CountC_all, TestDataset, Classlabels)\n",
    "    return np.array([resultlabel, resultprob])\n",
    "\n",
    "def ResultLPBayesClassifier(CountC_all, TestDataset, Classlabels):\n",
    "    ClassCounts_all = np.array(CountC_all)\n",
    "    resultlabel = np.full(np.alen(TestDataset), \"Indeterminate\", dtype=object)\n",
    "    resultprob = np.full(np.alen(TestDataset), 0 , dtype=float)\n",
    "    for g in range(len(TestDataset)):\n",
    "        CountXvalues = []\n",
    "        for w in range(len(Classlabels)):\n",
    "            count = ClassCounts_all[w][g]\n",
    "            CountXvalues.append(count)\n",
    "        max_value = max(CountXvalues)\n",
    "        max_index = CountXvalues.index(max_value)\n",
    "        label = Classlabels[max_index]\n",
    "        resultlabel[g]=label\n",
    "        #print sum(ClassCounts_all)\n",
    "        resultprob = (ClassCounts_all[max_index][g]).astype('float')/sum(ClassCounts_all)\n",
    "    return resultlabel, resultprob\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PerformanceMetrics(Resultlabels, Dataset, PositiveLabel,Classlabels):\n",
    "    OutputCL = (Resultlabels).astype('str')\n",
    "    GroundTruth = (Dataset[:,-1]).astype('str')\n",
    "    Classcomps = OutputCL == GroundTruth\n",
    "        \n",
    "    TrueP=0\n",
    "    FalseP=0\n",
    "    TrueN=0\n",
    "    FalseN=0\n",
    "    Num=0\n",
    "    for i in range(len(GroundTruth)):\n",
    "        if Classcomps[i]== True:\n",
    "            if OutputCL[i] == PositiveLabel:\n",
    "                TrueP+=1\n",
    "            else:\n",
    "                TrueN+=1\n",
    "        elif Classcomps[i]==False:\n",
    "            if OutputCL[i] != PositiveLabel:\n",
    "                FalseN+=1\n",
    "            else:\n",
    "                FalseP+=1\n",
    "    Accuracy = float((TrueP+TrueN))/(TrueP+TrueN+FalseP+FalseN)\n",
    "    Sensitivity = float((TrueP))/(TrueP+FalseN)\n",
    "    Specificity = float((TrueN))/(FalseP+TrueN)\n",
    "    PPV = float((TrueP))/(FalseP+TrueP)\n",
    "    stringmeasures = ['TrueP', 'FalseP', 'TrueN', 'FalseN', 'Accuracy', 'Sensitivity', 'Specificity', 'PPV']\n",
    "    measures_values = [TrueP, FalseP, TrueN, FalseN, Accuracy, Sensitivity, Specificity, PPV]\n",
    "    #print 'Classifier Performance:'\n",
    "    print '     Positive Class Label: '+ repr(PositiveLabel)\n",
    "    for i in range(len(stringmeasures)):\n",
    "        print '         '+stringmeasures[i]+ ': '+repr(measures_values[i])\n",
    "    \n",
    "    return [TrueP, FalseP, TrueN, FalseN, Accuracy, Sensitivity, Specificity, PPV]\n",
    "\n",
    "\n",
    "def BayesPCAperformance(TestDataset, TrainDataset, Classlabels, dimensions):\n",
    "    BayesPCAperformance =[]\n",
    "    DResults=EvaluateBayesPCA(TrainDataset, TestDataset, dimensions, Classlabels)\n",
    "    for i in range(len(DResults)):\n",
    "        print repr(i+2)+' Principal Components Bayes Classifier Performance:'\n",
    "        labelstring = []\n",
    "        reallabelstring = []\n",
    "        OutputCL = (DResults[i][0]).astype('str')\n",
    "        realCL=(TrainDataset[:,-1]).astype('str')\n",
    "        for j in range(len(Classlabels)):\n",
    "            labelnum = OutputCL[OutputCL == Classlabels[j]]\n",
    "            lstring = repr(Classlabels[j])+ ': '+ repr(len(labelnum))\n",
    "            labelstring.append(lstring)\n",
    "            reallabelnum = realCL[realCL == Classlabels[j]]\n",
    "            reallstring = repr(Classlabels[j])+ ': '+ repr(len(reallabelnum))\n",
    "            reallabelstring.append(reallstring)\n",
    "        print '  Training Output ->' + repr(reallabelstring) + ' Total: ' +repr(len(OutputCL))\n",
    "        print '  Testing Output -->' + repr(labelstring)+ ' Total: ' +repr(len(realCL))\n",
    "        for cl in range(len(Classlabels)):\n",
    "            PositiveLabel=Classlabels[cl]\n",
    "            nDBayesPerformance = PerformanceMetrics(DResults[i][0], TestDataset, PositiveLabel, Classlabels)\n",
    "            BayesPCAperformance.append(nDBayesPerformance)\n",
    "        print '\\n'\n",
    "    return np.array(BayesPCAperformance)\n",
    "\n",
    "def EvaluateBayesPCA(TrainDataset, TestDataset, dimensions, Classlabels):\n",
    "    DBayesPCAResults=[]\n",
    "    for d in range(dimensions-1):\n",
    "        D=d+2\n",
    "        nBResults = ApplyNDBayesianClassifier(TrainDataset, TestDataset, D, Classlabels)\n",
    "        DBayesPCAResults.append(nBResults)\n",
    "    return np.array(DBayesPCAResults)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Subset Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 7) (113, 7)\n",
      "(196, 7) (114, 7)\n"
     ]
    }
   ],
   "source": [
    "#2C data path\n",
    "v2C=r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/UBX - Machine Learning w: Python/FinalProject/vertebral_2C.xlsx\"\n",
    "#3C data path\n",
    "v3C =r\"/Volumes/Macintosh HD/Users/louisecabansay/Dropbox (Personal)/UBX - Machine Learning w: Python/FinalProject/vertebral_3C.xlsx\"\n",
    "#import matrices with class labels\n",
    "vdata2C=np.array(readExcel(v2C))\n",
    "vdata3C=np.array(readExcel(v3C))\n",
    "\n",
    "#set random seed to maintain results of single run\n",
    "random.seed(777)\n",
    "\n",
    "#call function to split given dataset into training and testing sets\n",
    "#note: not used for K-means as training/testing sets not needed\n",
    "[V2TrainDataset, V2TestDataset]=TestTrainDataSplit(vdata2C, 0.66)\n",
    "[V3TrainDataset, V3TestDataset]=TestTrainDataSplit(vdata3C, 0.66)\n",
    "\n",
    "#check training and test set size\n",
    "print V2TrainDataset.shape, V2TestDataset.shape\n",
    "print V3TrainDataset.shape, V3TestDataset.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run XUZCVPR and find principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-shape: (310, 6)\n",
      "U-shape: (1, 6)\n",
      "Z-shape: (310, 6)\n",
      "C-shape: (6, 6)\n",
      "V-shape: (6, 6)\n",
      "P-shape: (310, 6)\n",
      "R-shape: (310, 6)\n",
      "Xrec-shape: (310, 6)\n",
      "meanZround: [-0.0, -0.0, -0.0, 0.0, -0.0, -0.0]\n",
      "emptymeanZ: []\n",
      "C equals C.T : True\n",
      "Rows are eigenvectors if values are 1: array([ 1.,  1.,  1.,  1.,  1.,  1.])\n",
      "Note: Eigenvectors and values returned in order most to least importance\n"
     ]
    }
   ],
   "source": [
    "V2data = vdata2C[:,:-1]\n",
    "[V2X, V2U, V2Z, V2C, V2V, Evals, V2P, V2R, V2Xrec] = XUZCVPR(V2data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 principle component(s) the average difference between X and Xrec is 23.444807014459712\n",
      "Using 2 principle component(s) the average difference between X and Xrec is 16.725855662046349\n",
      "Using 3 principle component(s) the average difference between X and Xrec is 11.808577465741214\n",
      "Using 4 principle component(s) the average difference between X and Xrec is 6.9252607750171045\n",
      "Using 5 principle component(s) the average difference between X and Xrec is 0.0018012649481673707\n",
      "Using 6 principle component(s) the average difference between X and Xrec is 2.0453270783353266e-14\n"
     ]
    }
   ],
   "source": [
    "Xdiffavg= DimensionReduction(V2X, V2P, V2V, V2U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and Evaluate Binary Bayesian Classifier with d Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'NO': 57\", \"'AB': 140\"] Total: 113\n",
      "  Testing Output -->[\"'NO': 25\", \"'AB': 88\"] Total: 197\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 14\n",
      "         FalseP: 11\n",
      "         TrueN: 59\n",
      "         FalseN: 29\n",
      "         Accuracy: 0.6460176991150443\n",
      "         Sensitivity: 0.32558139534883723\n",
      "         Specificity: 0.8428571428571429\n",
      "         PPV: 0.56\n",
      "     Positive Class Label: 'AB'\n",
      "         TrueP: 59\n",
      "         FalseP: 29\n",
      "         TrueN: 14\n",
      "         FalseN: 11\n",
      "         Accuracy: 0.6460176991150443\n",
      "         Sensitivity: 0.8428571428571429\n",
      "         Specificity: 0.32558139534883723\n",
      "         PPV: 0.6704545454545454\n",
      "\n",
      "\n",
      "3 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'NO': 57\", \"'AB': 140\"] Total: 113\n",
      "  Testing Output -->[\"'NO': 33\", \"'AB': 80\"] Total: 197\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 19\n",
      "         FalseP: 14\n",
      "         TrueN: 56\n",
      "         FalseN: 24\n",
      "         Accuracy: 0.6637168141592921\n",
      "         Sensitivity: 0.4418604651162791\n",
      "         Specificity: 0.8\n",
      "         PPV: 0.5757575757575758\n",
      "     Positive Class Label: 'AB'\n",
      "         TrueP: 56\n",
      "         FalseP: 24\n",
      "         TrueN: 19\n",
      "         FalseN: 14\n",
      "         Accuracy: 0.6637168141592921\n",
      "         Sensitivity: 0.8\n",
      "         Specificity: 0.4418604651162791\n",
      "         PPV: 0.7\n",
      "\n",
      "\n",
      "4 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'NO': 57\", \"'AB': 140\"] Total: 113\n",
      "  Testing Output -->[\"'NO': 33\", \"'AB': 80\"] Total: 197\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 20\n",
      "         FalseP: 13\n",
      "         TrueN: 57\n",
      "         FalseN: 23\n",
      "         Accuracy: 0.6814159292035398\n",
      "         Sensitivity: 0.46511627906976744\n",
      "         Specificity: 0.8142857142857143\n",
      "         PPV: 0.6060606060606061\n",
      "     Positive Class Label: 'AB'\n",
      "         TrueP: 57\n",
      "         FalseP: 23\n",
      "         TrueN: 20\n",
      "         FalseN: 13\n",
      "         Accuracy: 0.6814159292035398\n",
      "         Sensitivity: 0.8142857142857143\n",
      "         Specificity: 0.46511627906976744\n",
      "         PPV: 0.7125\n",
      "\n",
      "\n",
      "5 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'NO': 57\", \"'AB': 140\"] Total: 113\n",
      "  Testing Output -->[\"'NO': 36\", \"'AB': 77\"] Total: 197\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 25\n",
      "         FalseP: 11\n",
      "         TrueN: 59\n",
      "         FalseN: 18\n",
      "         Accuracy: 0.7433628318584071\n",
      "         Sensitivity: 0.5813953488372093\n",
      "         Specificity: 0.8428571428571429\n",
      "         PPV: 0.6944444444444444\n",
      "     Positive Class Label: 'AB'\n",
      "         TrueP: 59\n",
      "         FalseP: 18\n",
      "         TrueN: 25\n",
      "         FalseN: 11\n",
      "         Accuracy: 0.7433628318584071\n",
      "         Sensitivity: 0.8428571428571429\n",
      "         Specificity: 0.5813953488372093\n",
      "         PPV: 0.7662337662337663\n",
      "\n",
      "\n",
      "6 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'NO': 57\", \"'AB': 140\"] Total: 113\n",
      "  Testing Output -->[\"'NO': 49\", \"'AB': 64\"] Total: 197\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 36\n",
      "         FalseP: 13\n",
      "         TrueN: 57\n",
      "         FalseN: 7\n",
      "         Accuracy: 0.8230088495575221\n",
      "         Sensitivity: 0.8372093023255814\n",
      "         Specificity: 0.8142857142857143\n",
      "         PPV: 0.7346938775510204\n",
      "     Positive Class Label: 'AB'\n",
      "         TrueP: 57\n",
      "         FalseP: 7\n",
      "         TrueN: 36\n",
      "         FalseN: 13\n",
      "         Accuracy: 0.8230088495575221\n",
      "         Sensitivity: 0.8142857142857143\n",
      "         Specificity: 0.8372093023255814\n",
      "         PPV: 0.890625\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V2Classlabels = ['NO','AB']\n",
    "dimensions = 6\n",
    "V2BayesPCAperformance = BayesPCAperformance(V2TestDataset, V2TrainDataset, V2Classlabels, dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'DH': 34\", \"'SL': 94\", \"'NO': 68\"] Total: 114\n",
      "  Testing Output -->[\"'DH': 15\", \"'SL': 56\", \"'NO': 43\"] Total: 196\n",
      "     Positive Class Label: 'DH'\n",
      "         TrueP: 10\n",
      "         FalseP: 5\n",
      "         TrueN: 61\n",
      "         FalseN: 38\n",
      "         Accuracy: 0.6228070175438597\n",
      "         Sensitivity: 0.20833333333333334\n",
      "         Specificity: 0.9242424242424242\n",
      "         PPV: 0.6666666666666666\n",
      "     Positive Class Label: 'SL'\n",
      "         TrueP: 43\n",
      "         FalseP: 13\n",
      "         TrueN: 28\n",
      "         FalseN: 30\n",
      "         Accuracy: 0.6228070175438597\n",
      "         Sensitivity: 0.589041095890411\n",
      "         Specificity: 0.6829268292682927\n",
      "         PPV: 0.7678571428571429\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 18\n",
      "         FalseP: 25\n",
      "         TrueN: 53\n",
      "         FalseN: 18\n",
      "         Accuracy: 0.6228070175438597\n",
      "         Sensitivity: 0.5\n",
      "         Specificity: 0.6794871794871795\n",
      "         PPV: 0.4186046511627907\n",
      "\n",
      "\n",
      "3 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'DH': 34\", \"'SL': 94\", \"'NO': 68\"] Total: 114\n",
      "  Testing Output -->[\"'DH': 19\", \"'SL': 48\", \"'NO': 47\"] Total: 196\n",
      "     Positive Class Label: 'DH'\n",
      "         TrueP: 12\n",
      "         FalseP: 7\n",
      "         TrueN: 60\n",
      "         FalseN: 35\n",
      "         Accuracy: 0.631578947368421\n",
      "         Sensitivity: 0.2553191489361702\n",
      "         Specificity: 0.8955223880597015\n",
      "         PPV: 0.631578947368421\n",
      "     Positive Class Label: 'SL'\n",
      "         TrueP: 41\n",
      "         FalseP: 7\n",
      "         TrueN: 31\n",
      "         FalseN: 35\n",
      "         Accuracy: 0.631578947368421\n",
      "         Sensitivity: 0.5394736842105263\n",
      "         Specificity: 0.8157894736842105\n",
      "         PPV: 0.8541666666666666\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 19\n",
      "         FalseP: 28\n",
      "         TrueN: 53\n",
      "         FalseN: 14\n",
      "         Accuracy: 0.631578947368421\n",
      "         Sensitivity: 0.5757575757575758\n",
      "         Specificity: 0.654320987654321\n",
      "         PPV: 0.40425531914893614\n",
      "\n",
      "\n",
      "4 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'DH': 34\", \"'SL': 94\", \"'NO': 68\"] Total: 114\n",
      "  Testing Output -->[\"'DH': 21\", \"'SL': 49\", \"'NO': 44\"] Total: 196\n",
      "     Positive Class Label: 'DH'\n",
      "         TrueP: 13\n",
      "         FalseP: 8\n",
      "         TrueN: 59\n",
      "         FalseN: 34\n",
      "         Accuracy: 0.631578947368421\n",
      "         Sensitivity: 0.2765957446808511\n",
      "         Specificity: 0.8805970149253731\n",
      "         PPV: 0.6190476190476191\n",
      "     Positive Class Label: 'SL'\n",
      "         TrueP: 41\n",
      "         FalseP: 8\n",
      "         TrueN: 31\n",
      "         FalseN: 34\n",
      "         Accuracy: 0.631578947368421\n",
      "         Sensitivity: 0.5466666666666666\n",
      "         Specificity: 0.7948717948717948\n",
      "         PPV: 0.8367346938775511\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 18\n",
      "         FalseP: 26\n",
      "         TrueN: 54\n",
      "         FalseN: 16\n",
      "         Accuracy: 0.631578947368421\n",
      "         Sensitivity: 0.5294117647058824\n",
      "         Specificity: 0.675\n",
      "         PPV: 0.4090909090909091\n",
      "\n",
      "\n",
      "5 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'DH': 34\", \"'SL': 94\", \"'NO': 68\"] Total: 114\n",
      "  Testing Output -->[\"'DH': 19\", \"'SL': 50\", \"'NO': 45\"] Total: 196\n",
      "     Positive Class Label: 'DH'\n",
      "         TrueP: 13\n",
      "         FalseP: 6\n",
      "         TrueN: 69\n",
      "         FalseN: 26\n",
      "         Accuracy: 0.7192982456140351\n",
      "         Sensitivity: 0.3333333333333333\n",
      "         Specificity: 0.92\n",
      "         PPV: 0.6842105263157895\n",
      "     Positive Class Label: 'SL'\n",
      "         TrueP: 44\n",
      "         FalseP: 6\n",
      "         TrueN: 38\n",
      "         FalseN: 26\n",
      "         Accuracy: 0.7192982456140351\n",
      "         Sensitivity: 0.6285714285714286\n",
      "         Specificity: 0.8636363636363636\n",
      "         PPV: 0.88\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 25\n",
      "         FalseP: 20\n",
      "         TrueN: 57\n",
      "         FalseN: 12\n",
      "         Accuracy: 0.7192982456140351\n",
      "         Sensitivity: 0.6756756756756757\n",
      "         Specificity: 0.7402597402597403\n",
      "         PPV: 0.5555555555555556\n",
      "\n",
      "\n",
      "6 Principal Components Bayes Classifier Performance:\n",
      "  Training Output ->[\"'DH': 34\", \"'SL': 94\", \"'NO': 68\"] Total: 114\n",
      "  Testing Output -->[\"'DH': 20\", \"'SL': 59\", \"'NO': 35\"] Total: 196\n",
      "     Positive Class Label: 'DH'\n",
      "         TrueP: 14\n",
      "         FalseP: 6\n",
      "         TrueN: 77\n",
      "         FalseN: 17\n",
      "         Accuracy: 0.7982456140350878\n",
      "         Sensitivity: 0.45161290322580644\n",
      "         Specificity: 0.927710843373494\n",
      "         PPV: 0.7\n",
      "     Positive Class Label: 'SL'\n",
      "         TrueP: 54\n",
      "         FalseP: 5\n",
      "         TrueN: 37\n",
      "         FalseN: 18\n",
      "         Accuracy: 0.7982456140350878\n",
      "         Sensitivity: 0.75\n",
      "         Specificity: 0.8809523809523809\n",
      "         PPV: 0.9152542372881356\n",
      "     Positive Class Label: 'NO'\n",
      "         TrueP: 23\n",
      "         FalseP: 12\n",
      "         TrueN: 68\n",
      "         FalseN: 11\n",
      "         Accuracy: 0.7982456140350878\n",
      "         Sensitivity: 0.6764705882352942\n",
      "         Specificity: 0.85\n",
      "         PPV: 0.6571428571428571\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V3Classlabels = ['DH','SL','NO']\n",
    "dimensions = 6\n",
    "V2BayesPCAperformance = BayesPCAperformance(V3TestDataset, V3TrainDataset, V3Classlabels, dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
